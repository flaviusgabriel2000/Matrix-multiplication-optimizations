// Matrix multiplication optimizations

STRUCTURING:
	The idea of my code to implement the project was to use the functions
from BLAS Atlas to implement matrix multiplications in an efficient manner
(with a complexity much better than O(n^3)), to apply the classic algorithm in O(n^3)
for matrix multiplication (the non-optimized variant), as well as to improve this
algorithm through pointer arithmetic and retaining variables in registers to
obtain better execution times.
	Also, the implementations do not have memory access problems,
which can be confirmed by the content of the .memory files in the memory directory.

IMPLEMENTATIONS:
	1. BLAS: I used two functions (cblas_dgemm and cblas_dtrmm) and worked directly
with the 3 matrices, without auxiliary variables. First, I multiplied B_t * B_t with
cblas_dgemm, storing the result in C. Then, I calculated A * B with cblas_dtrmm and wrote
the result in B. Finally, I calculated A * B * A_t (i.e. B * A_t) and added the result
in C.
	2. Neopt: Initially, we obtained the transposes of matrices A and B with the
transpose() function. Then, I followed the same principle as in the BLAS variant:
I did not use auxiliary variables, but stored the temporary results in the matrices
I had available, with the caveat that in the case of multiplications in which matrix A
appears, I took advantage of the fact that it is an upper triangular matrix.
	3. Opt_m: The same implementation as the Neopt algorithm, except that here I
eliminated vector accesses in exchange for pointer dereferencing, as well as using
the "register" keyword where appropriate.

ANALYSIS:
	1. Cachegrind: I refs means the number of instruction references,
D refs the number of data references, and Branches - the number of executed
jump instructions. As we expected, analyzing the .cache files, we notice that
the values are much smaller in the case of the BLAS variant, the number of
branches is approximately equal for the neopt and opt_m variants (as I said,
it is the same algorithm), and the highest values for I refs and D refs are
obtained, obviously, for the neopt variant.
	For opt_m we get smaller values, because we use pointer dereference
instead of vector accesses (the operation a[i][k] * b[k][j] requiring four
additions and two multiplications to obtain the addresses of a and b). Also,
c[i][j] is a constant, and in order not to do two additions and one multiplication
to obtain the address of c at each iteration, we will add the result of a[i][k] *
b[k][j] into a register that will eventually be assigned to c[i][j].
	2. Graphs: In the repo there are four graphs: one for each of the 3
implementations + a graph that includes all 3 variants.
Execution times:
	BLAS				 Neopt				Opt_m
N = 400  => T = 0.091296	N = 400  => T = 1.454513	N = 400  => T = 0.418508
N = 800  => T = 0.370214	N = 800  => T = 12.063025	N = 800  => T = 3.728475
N = 1000 => T = 0.694926	N = 1000 => T = 22.201445	N = 1000 => T = 5.941914
N = 1200 => T = 1.117271	N = 1200 => T = 40.991455	N = 1200 => T = 11.536547
N = 1400 => T = 1.710957	N = 1400 => T = 73.134331	N = 1400 => T = 20.959955

	Analyzing the runtimes and "Comparison plot.png", we notice that BLAS almost
overlaps the horizontal axis (much better complexity => much lower execution time),
while Neopt and Opt_m have an exponential growth with increasing N. On the graph we
realize how inefficient an O(n^3) algorithm can be.
